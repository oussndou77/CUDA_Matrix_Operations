# ğŸš€ CUDA Matrix Operations & LeNet-5 Implementation

## ğŸ“– Description
Ce projet explore l'utilisation de **CUDA** pour effectuer des opÃ©rations matricielles parallÃ¨les sur GPU et l'implÃ©mentation du rÃ©seau de neurones convolutif **LeNet-5**. L'objectif est de comprendre l'accÃ©lÃ©ration offerte par les GPU pour des calculs intensifs et de simuler un rÃ©seau convolutif complet.

---

## ğŸ¯ Objectifs
- ğŸ’¡ Comprendre le parallÃ©lisme avec CUDA.
- âš¡ Comparer les performances entre **CPU** et **GPU**.
- ğŸ§  ImplÃ©menter un rÃ©seau convolutif (**LeNet-5**) en C/CUDA.
- ğŸ” Ã‰tudier les rÃ©sultats et performances sur le dataset **MNIST**.

---

## âœ¨ FonctionnalitÃ©s
### Partie 1 : OpÃ©rations sur Matrices
1. Initialisation de matrices avec des valeurs alÃ©atoires.
2. Affichage des matrices sur CPU.
3. Addition et multiplication de matrices :
   - Sur **CPU**.
   - Sur **GPU** avec CUDA.

### Partie 2 : ImplÃ©mentation du LeNet-5
1. GÃ©nÃ©ration des donnÃ©es d'entrÃ©e pour MNIST.
2. Convolution 2D avec fonction d'activation **tanh**.
3. Sous-Ã©chantillonnage (moyennage 2x2).
4. Couches fully connected et activation **softmax**.
5. Tests avec les donnÃ©es MNIST et comparaison avec Python.

---

## ğŸ› ï¸ PrÃ©requis
- **CUDA Toolkit** (NVCC Compiler).
- Une carte graphique NVIDIA compatible CUDA.
- **MNIST Dataset** (fichiers binaires : `train-images.idx3-ubyte` et `train-labels.idx1-ubyte`).
- Environnement Linux ou Windows avec un Ã©diteur compatible.

---

## ğŸƒ Instructions pour les Tests
### Ã‰tape 1 : Compiler le programme
Utilisez la commande suivante pour compiler le fichier principal :
```bash
nvcc main.cu -o main
```

### Ã‰tape 2 : Lancer les tests
Pour effectuer les tests, exÃ©cutez la commande suivante avec les chemins appropriÃ©s pour les fichiers MNIST :
```bash
./main train-images.idx3-ubyte train-labels.idx1-ubyte
```

### Ã‰tape 3 : Tester une image spÃ©cifique
Pour tester une image particuliÃ¨re, ajoutez l'indice de l'image :
```bash
./main train-images.idx3-ubyte train-labels.idx1-ubyte 0
```

# ğŸ“Š RÃ©sultats des Tests

## Partie 1 : OpÃ©rations sur Matrices

| Taille \(n\) | Addition CPU (ms) | Addition GPU (ms) | Multiplication CPU (ms) | Multiplication GPU (ms) |
|--------------|--------------------|--------------------|--------------------------|--------------------------|
| 10           | 0                  | 0.33               | 2                        | 0.029                    |
| 1000         | 2                  | 0.296              | 2380                     | 2.802                    |
| 10000        | 216                | 7.445              | Pas de valeur (n trop grand) | 2789                 |

## Partie 2 : ImplÃ©mentation du LeNet-5

- **PrÃ©diction MNIST** : Le rÃ©seau prÃ©dit toujours la classe 0.

### Analyse des causes :

- ProblÃ¨mes potentiels dans le chargement des poids ou le prÃ©traitement des images.
- DiffÃ©rences dans l'architecture entre Python et CUDA.

### Comparaison des performances GPU vs CPU :

- AccÃ©lÃ©ration significative obtenue sur GPU pour les Ã©tapes convolutives et fully connected.

---

# ğŸŒŸ Ce que nous avons appris

- L'importance de l'alignement des poids, biais et dimensions entre le modÃ¨le Python et CUDA.
- L'efficacitÃ© du GPU pour les calculs massivement parallÃ¨les, notamment dans l'apprentissage profond.
- Les dÃ©fis de l'implÃ©mentation manuelle d'un rÃ©seau convolutif, tels que le prÃ©traitement des donnÃ©es et la gestion des paramÃ¨tres.

---

# ğŸ’¬ Remerciements

Ce projet a Ã©tÃ© rÃ©alisÃ© avec mon binÃ´me de TP, Mathys BARRIE, dont les idÃ©es et la collaboration ont Ã©tÃ© essentielles Ã  la rÃ©ussite de ce travail. ğŸ™Œ

# ğŸ“ Plus de dÃ©tails

Si vous souhaitez en savoir plus sur nos rÃ©sultats, n'hÃ©sitez pas Ã  consulter le dossier **Compte-Rendu** ğŸ“š, oÃ¹ vous trouverez un rÃ©sumÃ© dÃ©taillÃ© de notre travail. ğŸ”
